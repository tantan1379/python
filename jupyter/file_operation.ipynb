{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('pytorch': conda)"
  },
  "interpreter": {
   "hash": "e71563eb8b0d43ec289b891452eeda6f49ee0b171d226958b462f2af8160308f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#TODO 只保留每个病人18张图像\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "root =\"F:\\\\Dataset\\\\AMD_TimeSeries_CL\\\\\"\n",
    "for mat in os.listdir(root):\n",
    "    for one_v in os.listdir(os.path.join(root,mat)):\n",
    "        one_v_img = []\n",
    "        for img in os.listdir(os.path.join(root,mat,one_v)):\n",
    "            one_v_img.append(img)\n",
    "        print(len(one_v_img))\n",
    "        # os.remove(os.path.join(root,mat,one_v,one_v_img[0]))\n",
    "        # for i in range(18,len(one_v_img)):\n",
    "        #     os.remove(os.path.join(root,mat,one_v,one_v_img[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO 完成拥有前三次治疗图像的文件复制\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "\n",
    "root = \"F:\\\\Dataset\\\\ZhangSQ\\\\AMD\"\n",
    "des_path = \"F:\\\\Dataset\\\\AMD_TimeSeries_CL\"\n",
    "file_num = {}\n",
    "# 创建病人和治疗次数的hashmap:file_num\n",
    "for _,file_name,_ in os.walk(root):\n",
    "    for f in file_name:\n",
    "        num = f[5:9]\n",
    "        if num not in file_num.keys():\n",
    "            file_num[num]=1\n",
    "        else:\n",
    "            file_num[num]+=1\n",
    "# 选取治疗次数大于等于3次的病人数据\n",
    "select_num = []\n",
    "for key in file_num:\n",
    "    if file_num[key]>=4:\n",
    "        select_num.append(key)\n",
    "# 选取病人前三次的数据，保存为若干个列表\n",
    "dataV1toV3 = []\n",
    "for num in select_num:\n",
    "    one_pat = []\n",
    "    for i in range(1,4):\n",
    "        one_pat.append(os.path.join(root,\"01-A-\"+num+\"-V\"+str(i)+\"-OCT\"))\n",
    "    dataV1toV3.append(one_pat)\n",
    "# print(dataV1toV3)\n",
    "# 复制\n",
    "for one_pat in dataV1toV3:\n",
    "    one = []\n",
    "    # print(one_pat)\n",
    "    num = one_pat[0].split(os.sep)[-1][5:9]\n",
    "    if not os.path.exists(os.path.join(des_path,num)):\n",
    "        os.mkdir(os.path.join(des_path,num))\n",
    "    if not os.path.exists(os.path.join(des_path,num,\"V1\")):\n",
    "        os.mkdir(os.path.join(des_path,num,\"V1\"))\n",
    "    if not os.path.exists(os.path.join(des_path,num,\"V2\")):\n",
    "        os.mkdir(os.path.join(des_path,num,\"V2\"))\n",
    "    if not os.path.exists(os.path.join(des_path,num,\"V3\")):\n",
    "        os.mkdir(os.path.join(des_path,num,\"V3\"))\n",
    "    for one_v in one_pat:\n",
    "        if not os.path.exists(one_v):\n",
    "            break\n",
    "        for img in os.listdir(one_v):\n",
    "            shutil.copy(os.path.join(one_v,img),os.path.join(des_path,num,one_v.split(os.sep)[-1][10:12]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO read\n",
    "label = []\n",
    "tx = open(\"label.txt\")\n",
    "str1 = tx.read()\n",
    "tx.close()\n",
    "label.append([(str1)])\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO getitem\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "data = []\n",
    "label = []\n",
    "dataPath = \"F:\\\\Dataset\\\\AMD_TimeSeries_CL\\\\1_to_16_joint_resize\\\\\"\n",
    "for pat in os.listdir(dataPath):\n",
    "    patpath = dataPath + pat\n",
    "    frames = []\n",
    "    for i in range(1, 4):\n",
    "        imgname = '{}-V{}-OCT.jpg'.format(pat,i)\n",
    "        # img = cv2.imread(patpath + os.sep + imgname)\n",
    "        frames.append(imgname)\n",
    "    data.append(frames)\n",
    "    labelPath = patpath + os.sep + 'label.txt'\n",
    "    tx = open(labelPath)\n",
    "    str1 =tx.read()\n",
    "    tx.close()\n",
    "    label.append([int(str1)])\n",
    "# data = np.array(data)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO k fold\n",
    "import numpy as np\n",
    "\n",
    "dataPath = \"F:\\\\Dataset\\\\AMD_TimeSeries_CL\\\\1_to_16_joint_resize_label_requirement\\\\\"\n",
    "\n",
    "def get_img_label(dataPath):\n",
    "    imgs,labels = [],[]\n",
    "    for pat in os.listdir(dataPath):\n",
    "        patpath = dataPath + pat\n",
    "        frames = []\n",
    "        for i in range(1, 3+1):\n",
    "            imgname = '{}-V{}-OCT.jpg'.format(pat, i)\n",
    "            frames.append(patpath+os.sep+imgname)\n",
    "        imgs.append(frames)\n",
    "        labelPath = patpath + os.sep + 'label.txt'\n",
    "        tx = open(labelPath)\n",
    "        str1 = tx.read()\n",
    "        tx.close()\n",
    "        labels.append([int(str1)])\n",
    "    imgs = np.array(imgs)\n",
    "    labels = np.array(labels)\n",
    "    return imgs, labels\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    every_z_len = 104 // 5\n",
    "    ki=2\n",
    "    imgs,_ = get_img_label(dataPath)\n",
    "    # imgs = imgs[every_z_len*ki:every_z_len*(ki+1)]\n",
    "    # imgs = imgs[:every_z_len*ki]\n",
    "    imgs = np.vstack((imgs[every_z_len*(ki+1):],imgs[:every_z_len*ki]))\n",
    "\n",
    "    print(imgs.shape)\n",
    "    # print(len(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO test_file\n",
    "root = \"D:\\\\BaiduCloud\\\\roi_204\"\n",
    "des_root = \"F:\\\\MyGit\\\\jupyter\"\n",
    "import glob \n",
    "import os\n",
    "\n",
    "label_need = []\n",
    "for f in os.listdir(root):\n",
    "    pat_path = root + os.sep + f\n",
    "    # for label in os.listdir(pat_path):\n",
    "    label_need += glob.glob(os.path.join(pat_path,\"roi*_qianghua.nii\"))\n",
    "\n",
    "import shutil\n",
    "for iter,file in enumerate(label_need):\n",
    "    if(iter<5):\n",
    "        print(file)\n",
    "        shutil.copyfile(file,os.path.join(des_root,\"segmentation-{}.nii\".format(file.split(os.sep)[-1][4:7])))\n",
    "print(label_need)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "image_path = r\"F:\\Dataset\\CNV_Segmentation\\png_split\\img\"\n",
    "fold = sorted(os.listdir(image_path))\n",
    "fold_r = fold\n",
    "fold_r.remove('f'+str(1))\n",
    "img_list = []\n",
    "label_list = []\n",
    "for item in fold_r:\n",
    "    img_list+=glob.glob(os.path.join(image_path,item)+'/*.png')\n",
    "# print(img_list)\n",
    "label_list = [x.replace(\"img\",'mask').split('.')[0]+'.png' for x in img_list]\n",
    "print(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./testset/test.txt\",mode='a') as f:\n",
    "    print(\"1\",file=f)\n",
    "    print(\"2\",file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['.', 'checkpoints', 'cnv_seg_using_unet']\n"
     ]
    }
   ],
   "source": [
    "mypath = './checkpoints/' + 'cnv_seg_using_' + 'unet'\n",
    "print(mypath.split('/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}